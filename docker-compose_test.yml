services:
  web-service:
    container_name:  web-server-cuda
    image: namhoc123/cuda-whisper:1.3
    env_file:
      - .env
    command: "/app/prestart.sh"
    volumes:
      - ./web_server/app:/app/app
    ports:
      - 6007:6007
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0' ]
              capabilities: [ gpu ]


  triton-server:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: ai-platform-triton-server
    volumes:
      - ./triton_server/models:/models
    command: "tritonserver --model-repository=/models"
    ports:
      - 8000:8000
      - 8001:8001
      - 8002:8002